
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://ironbar.github.io/arc24/05_Solution_Summary/">
      
      
        <link rel="prev" href="../modeling/Iteration_n/">
      
      
        <link rel="next" href="../utils/00_Challenge_Workflow/">
      
      
      <link rel="icon" href="../res/arc_icon.jpg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.40">
    
    
      
        <title>Solution Summary - arc24</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#solution-summary" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="arc24" class="md-header__button md-logo" aria-label="arc24" data-md-component="logo">
      
  <img src="../res/arc_icon.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            arc24
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Solution Summary
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ironbar/arc24" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../01_Business_Understanding/" class="md-tabs__link">
        
  
    
  
  Business Understanding

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../02_Data_Understanding/" class="md-tabs__link">
        
  
    
  
  Data Understanding

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../03_State_of_the_art/" class="md-tabs__link">
        
  
    
  
  State of the art

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../modeling/" class="md-tabs__link">
          
  
    
  
  Modeling

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Solution Summary

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../utils/00_Challenge_Workflow/" class="md-tabs__link">
          
  
    
  
  Utils

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="arc24" class="md-nav__button md-logo" aria-label="arc24" data-md-component="logo">
      
  <img src="../res/arc_icon.jpg" alt="logo">

    </a>
    arc24
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ironbar/arc24" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_Business_Understanding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Business Understanding
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_Data_Understanding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Understanding
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../03_State_of_the_art/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    State of the art
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../modeling/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Modeling
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Modeling
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_01_few_shot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 1. Few-shot prompting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_02_learn_to_count/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 2. Learn to count
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_03_fine-tune_on_arc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 3. Fine-tune on ARC tasks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_04_test_time_fine-tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 4. Test time fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_05_search_for_smaller_llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 5. Search for smaller LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_06_ensemble_with_2020_solutions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 6. Ensemble with 2020 solution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_07_training_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 7. Training data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_08_code_improvements/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 8. Code improvements
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_09_improve_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 9. Improve inference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_10_improve_selection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 10. Improve response selection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_11_pseudo_beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 11. Pseudo beam-search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_12_grid_representation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 12. Grid representation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_13_single_task_ttft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 13. Single task test-time fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_14_speedup_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 14. Speedup training with unsloth
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_15_study_data_scaling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 15. Study how well this method scales with data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_16_next_steps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 16. Plan next steps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_17_external_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 17. Revisit external training data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_18_submission_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 18. Train models for submission
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_20_bigger_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 20. Bigger models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_21_more_data_augmentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 21. More data augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_22_learning_inputs_distribution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 22. Learning the inputs distribution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_23_more_external_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 23. More external data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_24_overfit_to_the_train_set/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 24. Overfit to the train set
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_25_decouple_ft_and_ttft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 25. Decouple fine-tuning and test-time fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_26_dawn_of_omni_arc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 26. Dawn of Omni-ARC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_27_fix_data_augmentation_bug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 27. Fix data augmentation bug
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_28_optimal_train_duration_and_capacity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 28. Optimal train duration and capacity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_29_qwen25/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 29. Qwen 2.5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_30_optimal_number_predictions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 30. Optimal number of predictions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_31_train_submission_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 31. Train new submission models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_32_llama_32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 32. Llama 3.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_33_back_to_smollm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 33. Back to SmolLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_34_developing_omni_arc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 34. Developing Omni-ARC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_35_optimize_batch_size/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 35. Optimize batch size
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_36_solving_evaluation_tasks_with_code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 36. Solving evaluation tasks with code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_37_optimize_code_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 37. Optimize code generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_38_make_non_instruct_models_great_again/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 38. Make non-instruct models great again
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_39_reduce_vllm_ram_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 39. Reduce VLLM RAM usage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_40_try_coding_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 40. Try coding models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_41_next_steps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 41. Next steps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_42_improve_omniarc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 42. Improve Omni-ARC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_43_train_a_verifier/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 43. Train a verifier
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_44_learn_to_use_strong_compute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 44. Learn to use Strong Compute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_45_improve_verifier/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 45. Improve the verifier approach
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_46_revisit_small_llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 46. Revisit small LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_47_select_instead_of_verify/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 47. Select instead of verify
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_48_more_external_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 48. More External data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_49_smolLM2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 49. SmolLM2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_50_last_trainings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 50. Last trainings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modeling/Iteration_n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration n. Iteration_title
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Solution Summary
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Solution Summary
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    <span class="md-ellipsis">
      Abstract
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intro" class="md-nav__link">
    <span class="md-ellipsis">
      Intro
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Intro">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#abstraction-and-reasoning-challenge" class="md-nav__link">
    <span class="md-ellipsis">
      Abstraction and Reasoning Challenge
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation-of-my-approach" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation of my approach
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Motivation of my approach">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-can-we-learn-from-few-high-dimensional-examples" class="md-nav__link">
    <span class="md-ellipsis">
      How can we learn from few high-dimensional examples?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-can-we-learn-a-good-representation-of-the-arc-problems" class="md-nav__link">
    <span class="md-ellipsis">
      How can we learn a good representation of the ARC problems?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#omni-arc-training-a-single-model-to-do-multiple-arc-related-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Omni-ARC: Training a single model to do multiple ARC-related tasks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prior-work" class="md-nav__link">
    <span class="md-ellipsis">
      Prior work
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Prior work">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindsai" class="md-nav__link">
    <span class="md-ellipsis">
      MindsAI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ryan-greenblatt" class="md-nav__link">
    <span class="md-ellipsis">
      Ryan Greenblatt
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#approach" class="md-nav__link">
    <span class="md-ellipsis">
      Approach
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Approach">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    <span class="md-ellipsis">
      Data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Problem augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Problem representation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      Training hyperparameters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-time-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Test-time fine-tuning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference" class="md-nav__link">
    <span class="md-ellipsis">
      Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ensemble" class="md-nav__link">
    <span class="md-ellipsis">
      Ensemble
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    <span class="md-ellipsis">
      Results
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learnings" class="md-nav__link">
    <span class="md-ellipsis">
      Learnings
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Learnings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prompting-is-not-enough-test-time-fine-tuning-is-needed" class="md-nav__link">
    <span class="md-ellipsis">
      Prompting is not enough, test-time fine-tuning is needed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#its-possible-to-train-the-model-to-verify-the-correctness-of-the-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      It's possible to train the model to verify the correctness of the tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solving-the-tasks-using-code-did-not-work-for-me" class="md-nav__link">
    <span class="md-ellipsis">
      Solving the tasks using code did not work for me
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-quality-of-the-datasets-is-relevant" class="md-nav__link">
    <span class="md-ellipsis">
      The quality of the datasets is relevant
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-right-model-size" class="md-nav__link">
    <span class="md-ellipsis">
      The right model size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-using-problem-augmentation-is-helpful" class="md-nav__link">
    <span class="md-ellipsis">
      Training using problem augmentation is helpful
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-the-inputs-distribution-is-helpful-to-solve-arc-problems" class="md-nav__link">
    <span class="md-ellipsis">
      Learning the inputs distribution is helpful to solve ARC problems
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#future-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Future steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#links" class="md-nav__link">
    <span class="md-ellipsis">
      Links
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acknowledgments" class="md-nav__link">
    <span class="md-ellipsis">
      Acknowledgments
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/00_Challenge_Workflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Challenge workflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/markdown_cheatsheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markdown cheatsheet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/methodology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Methodology
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    <span class="md-ellipsis">
      Abstract
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intro" class="md-nav__link">
    <span class="md-ellipsis">
      Intro
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Intro">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#abstraction-and-reasoning-challenge" class="md-nav__link">
    <span class="md-ellipsis">
      Abstraction and Reasoning Challenge
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation-of-my-approach" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation of my approach
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Motivation of my approach">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-can-we-learn-from-few-high-dimensional-examples" class="md-nav__link">
    <span class="md-ellipsis">
      How can we learn from few high-dimensional examples?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-can-we-learn-a-good-representation-of-the-arc-problems" class="md-nav__link">
    <span class="md-ellipsis">
      How can we learn a good representation of the ARC problems?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#omni-arc-training-a-single-model-to-do-multiple-arc-related-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Omni-ARC: Training a single model to do multiple ARC-related tasks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prior-work" class="md-nav__link">
    <span class="md-ellipsis">
      Prior work
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Prior work">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindsai" class="md-nav__link">
    <span class="md-ellipsis">
      MindsAI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ryan-greenblatt" class="md-nav__link">
    <span class="md-ellipsis">
      Ryan Greenblatt
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#approach" class="md-nav__link">
    <span class="md-ellipsis">
      Approach
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Approach">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    <span class="md-ellipsis">
      Data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Problem augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Problem representation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      Training hyperparameters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-time-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Test-time fine-tuning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference" class="md-nav__link">
    <span class="md-ellipsis">
      Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ensemble" class="md-nav__link">
    <span class="md-ellipsis">
      Ensemble
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    <span class="md-ellipsis">
      Results
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learnings" class="md-nav__link">
    <span class="md-ellipsis">
      Learnings
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Learnings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prompting-is-not-enough-test-time-fine-tuning-is-needed" class="md-nav__link">
    <span class="md-ellipsis">
      Prompting is not enough, test-time fine-tuning is needed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#its-possible-to-train-the-model-to-verify-the-correctness-of-the-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      It's possible to train the model to verify the correctness of the tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solving-the-tasks-using-code-did-not-work-for-me" class="md-nav__link">
    <span class="md-ellipsis">
      Solving the tasks using code did not work for me
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-quality-of-the-datasets-is-relevant" class="md-nav__link">
    <span class="md-ellipsis">
      The quality of the datasets is relevant
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-right-model-size" class="md-nav__link">
    <span class="md-ellipsis">
      The right model size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-using-problem-augmentation-is-helpful" class="md-nav__link">
    <span class="md-ellipsis">
      Training using problem augmentation is helpful
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-the-inputs-distribution-is-helpful-to-solve-arc-problems" class="md-nav__link">
    <span class="md-ellipsis">
      Learning the inputs distribution is helpful to solve ARC problems
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#future-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Future steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#links" class="md-nav__link">
    <span class="md-ellipsis">
      Links
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acknowledgments" class="md-nav__link">
    <span class="md-ellipsis">
      Acknowledgments
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="solution-summary">Solution Summary</h1>
<!--
https://www.kaggle.com/solution-write-up-documentation
https://www.kaggle.com/competitions/arc-prize-2024#paper-award

Here are some pointers from ARC Prize Co-founder François Chollet to help guide you in your paper submission writing.

Be sure to include:

- Abstract: Here’s what the contribution is (e.g., “we present a method to solve ARC-AGI, with the following characteristics…”)
- Intro: Let’s remind people about what ARC-AGI is, why it’s important, and let’s maybe quickly mention what the inspiration behind our approach was.
- Prior work: Here’s the list of previous approaches that are related to our approach.
  Note, they don’t have to have inspired your approach, they only need to be similar in some way - 
  they also don’t need to have been formally published as papers. Highlight similarities and differences. 
  Make sure that your approach still retains something unique (the contribution).
- Approach: Here’s how the approach works. Include an algorithm-level description. 
- Results: Here are the results we’re getting on ARC-AGI! Make sure to mention scores on various
  different sets, e.g., Kaggle leaderboard, public eval… And don’t report train set performance 
  - that’s not what the train set is for.
- Conclusion: Just quickly summarize what the contribution was and what you achieved. Can be 2 lines.

Optionally, you can also have some kind of “analysis” section where you discuss the various things you think you’ve learned from your experimental results (e.g., what kinds of tasks do you solve? Why? What kind of tasks are out of reach?)

Remember that shorter and clearer is always better. Absolutely no filler. Absolutely no attempt to act out sophistication for the sake of it. No equations unless they’re necessary to convey some concept formally.

Papers are about communicating your ideas clearly so that others can learn from them and reuse them. Don’t feel bad if your approach seems too “simple” when you write it down - that’s actually a great thing. There are no points for complication.
--->

<h2 id="abstract">Abstract</h2>
<p>This paper presents the Omni-ARC approach to the 2024 Abstraction and Reasoning Challenge (ARC), focusing on data efficiency and the abstraction aspect of the challenge. The core of this solution lies in training a transformer to perform multiple tasks related to ARC problems, going beyond the challenge's primary objective of predicting outputs from input-output examples. This multi-task learning approach aims to develop a robust representation of the ARC problem space.</p>
<p>Omni-ARC leverages publicly available LLMs, fine-tuning them on various ARC-related tasks, including output prediction and input distribution learning, using augmented data from multiple ARC datasets. The solution incorporates test-time fine-tuning to enhance accuracy on the private test set, achieving a score of 40 on the public leaderboard, securing 3rd place in the challenge.</p>
<p>Further analysis demonstrates the potential of training models to verify output correctness and select the most probable solution from multiple options, paving the way for future research in integrating reasoning capabilities into the Omni-ARC framework.</p>
<h2 id="intro">Intro</h2>
<h3 id="abstraction-and-reasoning-challenge">Abstraction and Reasoning Challenge</h3>
<p>There are two different definitions of artificial intelligence. The first says that artificial intelligence is
the science of creating machines that can do the tasks that humans can do. According to this definition
we would be very close to artificial general intelligence (AGI) because systems like ChatGPT can do many
tasks that only humans were able to do before such as solving math problems, answering all kind of questions,
improving the style of some text... Many AI researchers believe that scale is all we need, and simply
scaling the models and the data will lead to AGI.</p>
<p>But there is also another view championed by François Chollet that says that skill is not intelligence,
that intelligence is the ability to handle novelty and learn new skills.</p>
<blockquote>
<p>The intelligence of a system is a measure of its skill-acquisition efficiency over a scope of tasks, with respect to priors, experience, and generalization difficulty.</p>
</blockquote>
<p>According to this definition we are far from AGI because the accuracy of the current deep learning models
on some task does not depend on the complexity of the task, but on the familiarity of the model with the task.</p>
<p>To spark research into this view of intelligence Chollet created the Abstraction and Reasoning Corpus (ARC)
and so far it has resisted the test of time. Whereas LLMs are saturating all kind of publicly available
benchmarks, they still do very poorly on the ARC dataset. This can be explained by two big reasons:</p>
<ol>
<li>The test dataset is private</li>
<li>All the problems in the test dataset are novel</li>
</ol>
<p>In 2024 Chollet joined forces with Mike Knoop to launch the ARC Prize 2024, with a total prize pool of 1M$.
The goal was to rise awareness of the unbeaten ARC and to increase the number of people working to solve it.</p>
<h2 id="motivation-of-my-approach">Motivation of my approach</h2>
<p>In the <a href="https://arcprize.org/arc">ARC challenge</a> we have to learn a transformation rule given a few
high-dimensional pairs of input and output images. The images can have a size of up to 30x30 pixels
and each pixel can take 10 different colors. The images are not as complex as real world images, but nevertheless
they are high dimensional data.</p>
<h3 id="how-can-we-learn-from-few-high-dimensional-examples">How can we learn from few high-dimensional examples?</h3>
<p><img alt="representation is the key" src="../res/2024-11-08-12-32-46.png" /></p>
<p>To solve each ARC problem we have to find the <strong>right representation</strong> of the data. When humans solve the
tasks, the biggest challenge is to find the <strong>right perspective</strong> to look at the problem. Once we have the right
perspective of the data the ARC problems are trivial to solve.</p>
<p>The right representation of the data allows to decrease the dimensionality of the data and makes
possible to learn the transformation from very few examples.</p>
<!--
TODO: think of a better image
I don't like this image, don't know if helps.
![](res/2024-11-08-12-27-32.png)
--->

<h3 id="how-can-we-learn-a-good-representation-of-the-arc-problems">How can we learn a good representation of the ARC problems?</h3>
<p>If we train a model to do tasks that require a good representation of the data, it's likely that the
model will internally develop the required representation.</p>
<p>My insight was that we could use the ARC problems in many different ways to learn that representation,
not just in the original proposed task that asks to generate the output for an image given a few input-output pairs.
The next section shows the different ways to use the ARC problems.</p>
<h3 id="omni-arc-training-a-single-model-to-do-multiple-arc-related-tasks">Omni-ARC: Training a single model to do multiple ARC-related tasks</h3>
<table>
<thead>
<tr>
<th><strong>examples + input -&gt; output</strong></th>
<th><strong>examples -&gt; code</strong></th>
<th><strong>code + input -&gt; output</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="1" src="../modeling/res/2024-09-06-06-31-32.png" /></td>
<td><img alt="2" src="../modeling/res/2024-09-06-06-31-49.png" /></td>
<td><img alt="3" src="../modeling/res/2024-09-06-06-32-08.png" /></td>
</tr>
<tr>
<td><strong>inputs -&gt; input</strong></td>
<td><strong>code -&gt; inputs</strong></td>
<td><strong>inputs -&gt; code</strong></td>
</tr>
<tr>
<td><img alt="4" src="../modeling/res/2024-09-06-06-32-25.png" /></td>
<td><img alt="5" src="../modeling/res/2024-09-06-06-32-41.png" /></td>
<td><img alt="6" src="../modeling/res/2024-09-06-06-32-55.png" /></td>
</tr>
</tbody>
</table>
<ul>
<li><code>examples + input -&gt; output</code>. The original task of the ARC dataset.</li>
<li><code>inputs -&gt; input</code>. Generating new inputs requires to understand the distribution of the grids. It could also be done with the outputs, that should also follow some distribution.</li>
<li><code>examples -&gt; code</code>. This is the approach used by Ryan Greenblat with GPT-4o, generate code to solve the task given some ARC examples.</li>
<li><code>code + input -&gt; output</code>. This is equivalent to the first task, but instead of giving examples as input, it gives the code definition of the problem.</li>
<li><code>code -&gt; inputs</code>. Each input to a task follows some distribution, given a description of the
  distribution the model should be able to generate samples of that distribution.</li>
<li><code>inputs -&gt; code</code>. We could also do the opposite task, given some inputs write code to generate that distribution.</li>
<li><code>examples + input + output -&gt; is the output correct?</code>. It is possible to train the model to verify wether a proposed output is correct.</li>
<li><code>examples + input + output options-&gt; select the correct output</code>. We can train a model to select the correct output between multiple options.</li>
</ul>
<p>All the listed tasks require that the model learns some useful representation of the ARC image. The idea
behind the Omni-ARC approach is to train a single model to do all the tasks, with the expectation that a shared
representation across all the tasks will generalize better than training the model to do a single task.</p>
<p><img alt="omni-arc" src="../modeling/res/omni-arc.png" /></p>
<p><em>Omni-ARC, a single model that does all the ARC-related tasks (and it has a very cool logo)</em></p>
<h2 id="prior-work">Prior work</h2>
<h3 id="mindsai">MindsAI</h3>
<p>The most relevant prior work is the information given by the MindsAI team about they approach. On
interviews they have told that they biggest contribution is to do test-time fine-tuning. There was little
information but enough to make educated guesses and replicate their results:</p>
<ul>
<li><a href="https://lab42.global/community-interview-jack-cole/">Test-Time Augmentation to solve ARC, interview with Jack Cole</a></li>
<li><a href="https://youtu.be/jSAT_RuJ_Cg?si=-s_XpeeDA2BQYlVy">Machine Learning Street Talk | Chollet's ARC Challenge + Current Winners</a></li>
</ul>
<blockquote>
<p>Our ARC solution stands out due to several key elements. Firstly, we fine-tune models on synthetic and augmented data. Secondly, we employ test-time fine-tuning. Lastly, we have developed an approach called AIRV (augment, inference, reverse augmentation, and vote), which is analogous to test-time augmentation. These innovations are crucial, as transformer models perform relatively poorly on ARC without them.</p>
</blockquote>
<p>I could summarize my solution as an extension of the MindsAI approach, in addition to the three points
cited above my approach trains the model to perform more tasks around the ARC data. That way we can
improve the data efficiency of the system and get better results for the same amount of data.</p>
<h3 id="ryan-greenblatt">Ryan Greenblatt</h3>
<blockquote>
<p>I recently got to 50%1 accuracy on the public test set for ARC-AGI by having GPT-4o generate a huge number of Python implementations of the transformation rule (around 8,000 per problem) and then selecting among these implementations based on correctness of the Python programs on the examples (if this is confusing, go to the next section)2. I use a variety of additional approaches and tweaks which overall substantially improve the performance of my method relative to just sampling 8,000 programs.</p>
</blockquote>
<p>The <a href="https://redwoodresearch.substack.com/p/getting-50-sota-on-arc-agi-with-gpt">approach taken by Ryan Greenblatt</a> was very inspiring because he didn't fine-tune any model for the ARC challenge.</p>
<p>I tried to emulate his approach using open and smaller LLMs with the aim to combine it with the MindsAI
approach but my efforts failed. However I believe that if I devote more work to this approach it might work.</p>
<h2 id="approach">Approach</h2>
<!--
https://www.kaggle.com/code/ironbar/single-task-test-time-fine-tuning-for-arc24?scriptVersionId=199282752

v2: 20240925_submission_models/01_lora128-Qwen2.5-0.5B-Instruct_lr5e-5_4e4steps_2gpus_8192msl/checkpoint-40000/
v5: 20240925_submission_models/02_continue-lora128-Qwen2.5-0.5B-Instruct_lr5e-5_8e4steps_2gpus_8192msl/checkpoint-80000/
v8: 20240925_submission_models/03_continue-lora128-Qwen2.5-0.5B-Instruct_lr2.5e-5_8e4steps_2gpus_8192msl/checkpoint-80000/

/mnt/hdd0/Kaggle/arc24/models/20240925_submission_models/03_continue-lora128-Qwen2.5-0.5B-Instruct_lr2.5e-5_8e4steps_2gpus_8192msl/
-->

<p>The solution on a nutshell:</p>
<ol>
<li>Take <code>Qwen2.5-0.5B-Instruct</code> and fine-tune it on publicly available ARC datasets. The model was fine-tuned to:<ol>
<li>generate the outputs for the test samples</li>
<li>learn the inputs distribution and generate new inputs.</li>
</ol>
</li>
<li>Do test-time fine-tuning with the private test data, only for the task of generating the test outputs.</li>
<li>Inference with data augmentation, and voting to select the predictions</li>
<li>Ensemble with the 2020 public solution</li>
</ol>
<p><img alt="importance of the steps" src="../res/2024-11-11-11-55-30.png" /></p>
<h3 id="training">Training</h3>
<h4 id="data">Data</h4>
<p>I used the following publicly available datasets for training:</p>
<table>
<thead>
<tr>
<th>dataset</th>
<th>number of unique tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.kaggle.com/competitions/arc-prize-2024/data">original ARC dataset</a></td>
<td>800</td>
</tr>
<tr>
<td>Michael Hodel's <a href="https://github.com/michaelhodel/re-arc">RE-ARC dataset</a></td>
<td>400</td>
</tr>
<tr>
<td><a href="https://github.com/neoneye/arc-dataset-collection/tree/main/dataset/PQA">PQA dataset</a></td>
<td>7</td>
</tr>
<tr>
<td>Simon Strandgaard's <a href="https://github.com/neoneye/arc-dataset-tama">Tama dataset</a></td>
<td>50</td>
</tr>
<tr>
<td><a href="https://github.com/ksb21ST/Mini-ARC">Mini-ARC</a></td>
<td>149</td>
</tr>
<tr>
<td><a href="https://www.kaggle.com/datasets/zaharch/arc-nosound-tasks">nosound's hand crafted ARC tasks</a></td>
<td>9</td>
</tr>
<tr>
<td><a href="https://www.kaggle.com/datasets/andypenrose/extra-arc-tasks-for-testing">Andy Penrose's tasks</a></td>
<td>5</td>
</tr>
<tr>
<td>TOTAL</td>
<td>1420</td>
</tr>
</tbody>
</table>
<p>For all the datasets I trained the model to do two tasks:</p>
<ul>
<li><code>examples + input -&gt; output</code>. The original task of the ARC dataset.</li>
<li><code>inputs -&gt; input</code>. Generating new inputs requires to understand the distribution of the grids. It could also be done with the outputs, that should also follow some distribution.</li>
</ul>
<details class="note">
<summary>Click to see examples of newly generated inputs</summary>
<p><img alt="" src="../modeling/res/2024-09-14-08-34-47.png" /></p>
<p><img alt="" src="../modeling/res/2024-09-14-08-35-16.png" /></p>
<p><img alt="" src="../modeling/res/2024-09-14-08-36-04.png" /></p>
<p><img alt="" src="../modeling/res/2024-09-14-08-39-28.png" /></p>
<p><img alt="" src="../modeling/res/2024-09-14-08-39-44.png" /></p>
<p><img alt="" src="../modeling/res/2024-09-14-08-40-01.png" /></p>
<p><img alt="" src="../modeling/res/2024-09-14-08-40-23.png" /></p>
</details>
<h4 id="data-augmentation">Data augmentation</h4>
<p>For each problem the same data augmentation was applied to all the inputs and outputs. Data augmentation
was a composition of the following augmentations:</p>
<ul>
<li>Rotations</li>
<li>Flips</li>
<li>Color changes</li>
<li>Swap between train and test examples</li>
</ul>
<h4 id="problem-augmentation">Problem augmentation</h4>
<p>In addition to the data augmentation I also did problem augmentation by applying a transformation
only to the inputs or to the outputs. This transformation created new ARC problems by composing the
original ARC transformation with randomly chosen new ones.</p>
<p>These new transformations needed to be reversible, otherwise the new generated problems might not
be solvable. I used the following additional transformations:</p>
<ul>
<li>Rotations and/or flips</li>
<li>Padding the image</li>
<li>Upscale</li>
<li>Mirror</li>
</ul>
<details class="note">
<summary>Click to see examples of problem augmentation</summary>
<p>Original task:</p>
<p><img alt="" src="../res/2024-11-11-10-27-59.png" /></p>
<p>Rotate the inputs:</p>
<p><img alt="" src="../res/2024-11-11-10-28-22.png" /></p>
<p>Upscale x2 the outputs:</p>
<p><img alt="" src="../res/2024-11-11-10-28-44.png" /></p>
<p>Add padding to the inputs:</p>
<p><img alt="" src="../res/2024-11-11-10-29-10.png" /></p>
<p>Mirroring the outputs:</p>
<p><img alt="" src="../res/2024-11-11-10-29-50.png" /></p>
</details>
<h4 id="problem-representation">Problem representation</h4>
<p>I used a very simple text representation of the ARC grids as an input to the LLMs. The grid was enclosed
on a Markdown code snippet, the shape was defined at the first line and each row was numbered.</p>
<pre><code>```grid shape: 3x3
1 100
2 010
3 001
```
</code></pre>
<h4 id="training-hyperparameters">Training hyperparameters</h4>
<p>The model was fine-tuned using LoRA. No significative improvement was found when doing full model fine-tuning and
also on test-time fine-tuning it seemed to be beneficial to just fine-tune the already trained LoRA adapter
instead of creating a fresh new adapter.</p>
<ul>
<li>Model: <code>Qwen2.5-0.5B-Instruct</code></li>
<li>LoRA rank: 128 (17M of parameters)</li>
<li>Learning rate: 5e-5, with a linear schedule with warmup</li>
<li>Batch size: 16</li>
<li>Training steps: 2e5</li>
<li>Max sequence length: 8196</li>
<li>Trained on 2xA6000 GPUs</li>
</ul>
<p>I used huggingface's trl and accelerate libraries for the training.</p>
<h3 id="test-time-fine-tuning">Test-time fine-tuning</h3>
<p>Fine-tuning a model on ARC tasks is not enough to do well on the private test set. By applying test-time fine-tuning we could improve the number of solved problems from 11 to 33 for one of the models that I trained along the challenge.</p>
<p>This is my interpretation of the test-time fine-tuning:</p>
<ul>
<li>For each test problem that had <code>n</code> train samples, I fine-tuned the model using <code>n-1</code> train samples and
  using the remaining sample as a test sample. The selection of the test sample was done randomly on the fly during training.</li>
<li>I used <a href="#data-augmentation">data augmentation</a> just like in the previous training</li>
<li>I fine-tuned a model for each of the test problems, so 100 fine-tuned models were generated on each submission.</li>
<li>I used batch size 1 in the test-time fine-tuning to be able to learn the new problems as fast as possible.</li>
<li>The model was fine-tuned for ~300 steps on each problem</li>
<li>Suprisingly the best learning rate for test-time fine-tuning was 8e-5, higher than the one used for
  training (5e-5). It's very likely that better results could be obtained if more computation was
  available, training with a slower learning rate, with higher batch size and for longer.</li>
</ul>
<p>Due to the limited submission time test-time fine-tuning was only applied to the canonical ARC task
of predicting the test outputs. But it could also be applied to the task of generating new inputs, or
to the tasks of verifying the correctness of the outputs.</p>
<p>The unusual configuration of training a single model for each task with batch size 1 arose due to the
limitations of compute and submission time. It was the configuration that allowed to learn faster the new
test problems.</p>
<h3 id="inference">Inference</h3>
<p>Data augmentation was applied also at inference, and the data augmentation was reverted from the prediction to get the original output. 96 predictions were done for each problem and voting was used to select the most
promising predictions. So just like MindsAI's AIRV (augment, inference, reverse augmentation, and vote).</p>
<p>Inference was done using a temperature of 0.</p>
<p><a href="https://github.com/vllm-project/vllm">vLLM</a> was used to generate the predictions. Each fine-tuned model was used to generate predictions for its problem.</p>
<h3 id="ensemble">Ensemble</h3>
<p>I ensembled my model predictions with the <a href="https://www.kaggle.com/code/mehrankazeminia/3-arc24-developed-2020-winning-solutions">2020 solution</a>. Since the 2020 solution only requires CPU, I managed to run
it on the background while I used the GPU for fine-tuning and inference with my model. I only had to
be careful with the RAM usage because both jobs had to share the same memory.</p>
<p>The ensemble strategy was very simple, just take the first attempt from each solution.</p>
<h3 id="results">Results</h3>
<p>This approach scored 40 on the ARC leaderboard.</p>
<p><img alt="importance of the steps" src="../res/2024-11-11-11-55-30.png" /></p>
<p>The same approach (without test-time fine-tuning) could solve 32% of the evaluation tasks, and when using voting with 32 predictions
it achieved a top_2 accuracy of 22%. Due to limited hardware resources I didn't usually evaluate
the models with test-time fine-tuning on the evaluation dataset. Kaggle provides 30 hours of GPU each week,
but we could make 3 submissions a day which is equivalent to 36 hours of compute. Thus it was much
cheaper to use the submissions to see the performance of the test-time fine-tuning where we had 7 times
more compute available per week.</p>
<h2 id="learnings">Learnings</h2>
<h3 id="prompting-is-not-enough-test-time-fine-tuning-is-needed">Prompting is not enough, test-time fine-tuning is needed</h3>
<p>Clearly this competition has shown that LLMs need test-time fine-tuning to do new tasks. Few-shot prompting is not enough for the model to learn novel tasks.</p>
<h3 id="its-possible-to-train-the-model-to-verify-the-correctness-of-the-tasks">It's possible to train the model to verify the correctness of the tasks</h3>
<p>During the last weeks of the challenge I tried to continue with the Omni-ARC approach and train the model to:</p>
<ol>
<li>Verify if an output is correct</li>
<li>Select the correct output between two options</li>
</ol>
<p>The idea was that we could improve the leaderboard (LB) score if we replaced the voting selection mechanism by a more accurate one.
Using trained models I generated wrong predictions for the original ARC dataset using a sampling temperature close to 1.</p>
<table>
<thead>
<tr>
<th>method</th>
<th>top 1 accuracy</th>
<th>top 2 accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>voting</td>
<td>60.0%</td>
<td>70.0%</td>
</tr>
<tr>
<td>verification</td>
<td>59.3%</td>
<td>77.4%</td>
</tr>
<tr>
<td>selection</td>
<td><strong>68.7%</strong></td>
<td><strong>81.0%</strong></td>
</tr>
</tbody>
</table>
<p>As the table above shows I was able to achieve promising results on the evaluation dataset. Those numbers are for 32 predictions.</p>
<p>However I was not able to improve the LB score using this approach. My hypothesis is that the distribution
of the predictions of a test-time fine-tuned model is different from the distribution of a frozen model. Thus
the accuracy of voting for a test-time fine-tuned model might be much higher than the shown in the table
for a frozen model.</p>
<p>This verifier models could benefit from test-time fine-tuning, but I could not test the hypothesis due
to the limited submission time.</p>
<p>More information on <a href="../modeling/Iteration_47_select_instead_of_verify/">Iteration 47</a> and <a href="../modeling/Iteration_45_improve_verifier/">Iteration 45</a>.</p>
<h3 id="solving-the-tasks-using-code-did-not-work-for-me">Solving the tasks using code did not work for me</h3>
<p>I also tried to expand on the Omni-ARC approach by training the model to do the additional tasks:</p>
<ul>
<li><code>examples -&gt; code</code>. This is the approach used by Ryan Greenblat with GPT-4o</li>
<li><code>code + input -&gt; output</code>. This is equivalent to the first task, but instead of giving examples as input, it gives the code definition of the problem.</li>
</ul>
<p>To do so I built a small domain specific language (DSL) and recreated 285 of the ARC training tasks
with python code. This was a laborious process that took around 3 weeks.</p>
<p>Unfortunately the model did not generalize well. It could only solve 5% of the evaluation tasks, and those
tasks were very similar to the training tasks. On the private test set a lucky submission was able to
solve 1 task.</p>
<p>I believe this approach has great potential, but I had to change to other approaches because the end
of the challenge was close and other teams were improving in the leaderboard.</p>
<p>More info on <a href="../modeling/Iteration_26_dawn_of_omni_arc/">Iteration 26</a>, <a href="../modeling/Iteration_40_try_coding_models/">Iteration 40</a> and <a href="../modeling/Iteration_42_improve_omniarc/">Iteration 42</a>.</p>
<h3 id="the-quality-of-the-datasets-is-relevant">The quality of the datasets is relevant</h3>
<p>On the last weeks of the challenge I tried adding the <a href="https://huggingface.co/collections/barc0/synthetic-arc-dataset-6725aa6031376d3bacc34f76">BARC datasets</a> to the training data. Surprisingly despite the enormous
claimed number of different tasks (400k) I did not see any significative improvement either on the
evaluation dataset or in the leaderboard. More information on <a href="../modeling/Iteration_48_more_external_data/">Iteration 48. More external data</a>.</p>
<p>This is surprising because the original ARC dataset shows a clear trend when increasing the number
of training tasks:</p>
<p><img alt="data-scaling" src="../modeling/res/2024-09-02-16-02-17.png" /></p>
<p>My guess is that the automatically generated tasks by GPT4 did not have too much novelty respect
to the original ARC tasks.</p>
<h3 id="the-right-model-size">The right model size</h3>
<p><code>Qwen2.5-0.5B</code> was the right model size for my approach and the available compute for submission.</p>
<p>On a first step I tried smaller models such as <code>SmolLM2-135M</code> and <code>NanoLM-0.3B</code> but they did not
achieve the same accuracy as <code>Qwen2.5-0.5B</code>. More on <a href="../modeling/Iteration_46_revisit_small_llms/">Iteration 46. Revisit small LLMs</a></p>
<p>On my <a href="../modeling/Iteration_50_last_trainings/">final attempt</a> I also tried bigger models such as <code>Qwen2.5-1.5B</code> and <code>Qwen2.5-7B</code>.
These models exhibit a higher data efficiency, they reach a smaller training loss for the same amount
of training steps. The problem with these models is that they are slower to fine-tune and inference at submission.
Moreover due to VRAM requirements we have to decrease the length of the training samples. It's very
likely that LB score could be improved with this bigger models if better hardware and more submission
time is given.</p>
<h3 id="training-using-problem-augmentation-is-helpful">Training using problem augmentation is helpful</h3>
<p>The plot below shows the accuracy of a model on the evaluation dataset when being trained with a different
amount of problem augmentation. Using problem augmentation 50% of the times seems to be the best option. Accuracy measures how many of the predictions made by the model are correct and it's a more robust and stable metric than vote_2 or pass_n (because it is computed with a bigger number of samples).</p>
<p><img alt="problem augmentation" src="../res/2024-11-12-09-33-08.png" /></p>
<p>More info on <a href="../modeling/Iteration_21_more_data_augmentation/">Iteration 21. More data augmentation</a></p>
<h3 id="learning-the-inputs-distribution-is-helpful-to-solve-arc-problems">Learning the inputs distribution is helpful to solve ARC problems</h3>
<p>The table below shows the results on the evaluation dataset of an experiment that tried to see if
learning the inputs and/or the outputs distribution was helpful. There is a clear improvement on accuracy
when learning the inputs distribution. However learning the outputs distribution does not seem to be
helpful.</p>
<table>
<thead>
<tr>
<th>new tasks</th>
<th>accuracy</th>
<th>correct_pixels</th>
<th>correct_size</th>
<th>pass_n</th>
<th>vote_2</th>
</tr>
</thead>
<tbody>
<tr>
<td>-</td>
<td>4.61%</td>
<td>68.54%</td>
<td>87.34%</td>
<td>17.25%</td>
<td>10.73%</td>
</tr>
<tr>
<td>5k inputs</td>
<td><strong>5.36%</strong></td>
<td><strong>69.40%</strong></td>
<td><strong>88.38%</strong></td>
<td><strong>19.75%</strong></td>
<td><strong>13.13%</strong></td>
</tr>
<tr>
<td>5k inputs, 5k outputs</td>
<td>5.13%</td>
<td>68.34%</td>
<td>87.18%</td>
<td><strong>19.75%</strong></td>
<td>12.37%</td>
</tr>
<tr>
<td>2.5k inputs 2.5k outputs</td>
<td>4.68%</td>
<td>68.55%</td>
<td>87.66%</td>
<td>17.38%</td>
<td>11.99%</td>
</tr>
</tbody>
</table>
<p><a href="../modeling/Iteration_22_learning_inputs_distribution/">Iteration 22. Learning the inputs distribution</a></p>
<h2 id="conclusion">Conclusion</h2>
<h2 id="future-steps">Future steps</h2>
<p>The approach of using a transformer and test-time fine-tuning could likely keep improving and maybe
solve the ARC prize if we generate enough synthetic data to densely cover the space of the ARC problems.
However that kind of solution won't give us more knowledge about how to reach AGI. It might be worth
pursuing that direction just to know where it can get us, but I don't feel it is interesting.</p>
<p>On this year competition I have focused on abstraction, on building the best possible representation
of the ARC problems. But the reasoning part was missing from my solution. When I try to solve the ARC
problems I make a hypothesis of the transformation, see if it works on the train data and fix it if
it doesn't. Finding the solution is typically an iterative process of trial and error.</p>
<p>I believe that we can teach a model to reason, just like OpenAI is developing the new o1 models. First we will
need to have a model that is able to generate code to solve the problems, otherwise we cannot verify
the solution and iterate over the results. Then we will generate many reasoning traces for the training
tasks and the model could learn to iteratively create a python code solution to the problems. The main
obstacle that I see to this approach is that it will require a much bigger context size than the current
MindsAI approach because in addition to the original task the prompt will also have the different
code iterations and the outputs. So we could be talking about using up to 50k tokens instead of the
current 10k tokens. That requires better hardware both for training and inference.</p>
<p>Probably the best approach is the one that first tries to generate code to solve the problems and finally
uses test-time fine-tuning only on the problems that the code approach could not solve. Thus I believe that
the Omni-ARC approach, training a single model to do multiple ARC-related tasks, has a great change of
being used in the solution that beats the 85% goal.</p>
<p>Finally I'm going to buy an <a href="https://amzn.eu/d/efqVvEh">Omni-man funko pop figure</a> to celebrate the prize.</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="https://ironbar.github.io/arc24/">Documentation of all the work done during the challenge</a></li>
<li><a href="https://github.com/ironbar/arc24">Github repo</a></li>
<li><a href="https://www.kaggle.com/code/ironbar/single-task-test-time-fine-tuning-for-arc24?scriptVersionId=199282752">Submission notebook</a></li>
<li><a href="https://www.kaggle.com/competitions/arc-prize-2024/discussion/545671">Kaggle post</a></li>
<li>TODO: create a <a href="https://www.youtube.com/@guillermobarbadillo">Youtube video</a> explaining my approach and comparing to other teams solutions.</li>
<li><a href="https://notebooklm.google.com/notebook/cf13e950-4048-4ba6-a001-e3d03a577339/audio">NotebookLM podcast</a></li>
<li><a href="https://www.linkedin.com/in/guillermobarbadillo/">LinkedIn profile</a></li>
<li><a href="https://x.com/guille_bar">Twitter profile</a></li>
</ul>
<h2 id="acknowledgments">Acknowledgments</h2>
<ul>
<li><a href="https://veridas.com/en/">Veridas</a> for providing me access to its compute cluster during all the challenge. Most of the experiments were done on Veridas cluster, using A6000 GPUs with 48GB of VRAM.</li>
<li><a href="https://strongcompute.com/">Strong Compute</a> for providing compute for training the last models for
  the challenge. They gave me access to A100 GPUs with 80GB of VRAM, which allowed me to train bigger models.</li>
<li><a href="https://huggingface.co/Qwen">Qwen</a> for training and releasing a family of very capable LLMs with
  many different sizes.</li>
<li><a href="https://wandb.ai/home">Weigths and Biases</a> I used it to track all the experiments in a single place.
  It's an amazing tool and free for individuals.</li>
<li><a href="https://lambdalabs.com/">Lambdalabs</a>. I did some short (but expensive) experiments on the last
  week of the challenge in Lambdalabs. They provide me with some free credits that partially covered
  this experiments.</li>
<li>ARC team. It's been a pleasure to work in this super interesting challenge for a few months. Thanks
  for creating the challenge and specially to Chollet for all his wisdom and teachings.</li>
<li>Family. I couldn't have done all this work without the help of my wife and the appreciation from
  my children. My family followed my progress during the challenge and cheered me up when I advanced in the leaderboard.</li>
</ul>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    2024-12-08
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/guillermobarbadillo/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/guille_bar" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/channel/UCOHmUwHnd2hmUpiDzaQ1Isg" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.kaggle.com/ironbar" target="_blank" rel="noopener" title="www.kaggle.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M304.2 501.5 158.4 320.3 298.2 185c2.6-2.7 1.7-10.5-5.3-10.5h-69.2c-3.5 0-7 1.8-10.5 5.3L80.9 313.5V7.5q0-7.5-7.5-7.5H21.5Q14 0 14 7.5v497q0 7.5 7.5 7.5h51.9q7.5 0 7.5-7.5v-109l30.8-29.3 110.5 140.6c3 3.5 6.5 5.3 10.5 5.3h66.9q5.25 0 6-3z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.525ec568.min.js"></script>
      
        <script src="../javascript/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>