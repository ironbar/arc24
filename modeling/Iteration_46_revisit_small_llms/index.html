
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://ironbar.github.io/arc24/modeling/Iteration_46_revisit_small_llms/">
      
      
        <link rel="prev" href="../Iteration_45_improve_verifier/">
      
      
        <link rel="next" href="../Iteration_47_select_instead_of_verify/">
      
      
      <link rel="icon" href="../../res/arc_icon.jpg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.40">
    
    
      
        <title>Iteration 46. Revisit small LLMs - arc24</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8c3ca2c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#iteration-46-revisit-small-llms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="arc24" class="md-header__button md-logo" aria-label="arc24" data-md-component="logo">
      
  <img src="../../res/arc_icon.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            arc24
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Iteration 46. Revisit small LLMs
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ironbar/arc24" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../01_Business_Understanding/" class="md-tabs__link">
        
  
    
  
  Business Understanding

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../02_Data_Understanding/" class="md-tabs__link">
        
  
    
  
  Data Understanding

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../03_State_of_the_art/" class="md-tabs__link">
        
  
    
  
  State of the art

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Modeling

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../05_Solution_Summary/" class="md-tabs__link">
        
  
    
  
  Solution Summary

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../utils/00_Challenge_Workflow/" class="md-tabs__link">
          
  
    
  
  Utils

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="arc24" class="md-nav__button md-logo" aria-label="arc24" data-md-component="logo">
      
  <img src="../../res/arc_icon.jpg" alt="logo">

    </a>
    arc24
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ironbar/arc24" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01_Business_Understanding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Business Understanding
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02_Data_Understanding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Understanding
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03_State_of_the_art/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    State of the art
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Modeling
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Modeling
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_01_few_shot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 1. Few-shot prompting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_02_learn_to_count/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 2. Learn to count
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_03_fine-tune_on_arc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 3. Fine-tune on ARC tasks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_04_test_time_fine-tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 4. Test time fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_05_search_for_smaller_llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 5. Search for smaller LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_06_ensemble_with_2020_solutions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 6. Ensemble with 2020 solution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_07_training_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 7. Training data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_08_code_improvements/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 8. Code improvements
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_09_improve_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 9. Improve inference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_10_improve_selection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 10. Improve response selection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_11_pseudo_beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 11. Pseudo beam-search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_12_grid_representation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 12. Grid representation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_13_single_task_ttft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 13. Single task test-time fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_14_speedup_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 14. Speedup training with unsloth
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_15_study_data_scaling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 15. Study how well this method scales with data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_16_next_steps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 16. Plan next steps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_17_external_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 17. Revisit external training data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_18_submission_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 18. Train models for submission
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_20_bigger_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 20. Bigger models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_21_more_data_augmentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 21. More data augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_22_learning_inputs_distribution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 22. Learning the inputs distribution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_23_more_external_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 23. More external data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_24_overfit_to_the_train_set/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 24. Overfit to the train set
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_25_decouple_ft_and_ttft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 25. Decouple fine-tuning and test-time fine-tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_26_dawn_of_omni_arc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 26. Dawn of Omni-ARC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_27_fix_data_augmentation_bug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 27. Fix data augmentation bug
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_28_optimal_train_duration_and_capacity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 28. Optimal train duration and capacity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_29_qwen25/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 29. Qwen 2.5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_30_optimal_number_predictions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 30. Optimal number of predictions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_31_train_submission_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 31. Train new submission models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_32_llama_32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 32. Llama 3.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_33_back_to_smollm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 33. Back to SmolLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_34_developing_omni_arc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 34. Developing Omni-ARC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_35_optimize_batch_size/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 35. Optimize batch size
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_36_solving_evaluation_tasks_with_code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 36. Solving evaluation tasks with code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_37_optimize_code_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 37. Optimize code generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_38_make_non_instruct_models_great_again/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 38. Make non-instruct models great again
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_39_reduce_vllm_ram_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 39. Reduce VLLM RAM usage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_40_try_coding_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 40. Try coding models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_41_next_steps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 41. Next steps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_42_improve_omniarc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 42. Improve Omni-ARC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_43_train_a_verifier/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 43. Train a verifier
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_44_learn_to_use_strong_compute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 44. Learn to use Strong Compute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_45_improve_verifier/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 45. Improve the verifier approach
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Iteration 46. Revisit small LLMs
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Iteration 46. Revisit small LLMs
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#goal" class="md-nav__link">
    <span class="md-ellipsis">
      Goal
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#development" class="md-nav__link">
    <span class="md-ellipsis">
      Development
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Development">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#available-options" class="md-nav__link">
    <span class="md-ellipsis">
      Available options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adding-a-chat-template" class="md-nav__link">
    <span class="md-ellipsis">
      Adding a chat template
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adding a chat template">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#problems-when-adding-the-chat-template" class="md-nav__link">
    <span class="md-ellipsis">
      Problems when adding the chat template
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#local-trainings-to-verify-i-can-train-the-small-models" class="md-nav__link">
    <span class="md-ellipsis">
      Local trainings to verify I can train the small models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debug-long-context-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Debug long context fine-tuning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-when-resuming-training" class="md-nav__link">
    <span class="md-ellipsis">
      Error when resuming training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-with-smollm-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      Problem with SmolLM predictions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    <span class="md-ellipsis">
      Results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#increasing-the-context-length-by-increasing-rope_theta" class="md-nav__link">
    <span class="md-ellipsis">
      Increasing the context length by increasing rope_theta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-evaluation-results" class="md-nav__link">
    <span class="md-ellipsis">
      First evaluation results
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#studying-training-dynamics" class="md-nav__link">
    <span class="md-ellipsis">
      Studying training dynamics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Studying training dynamics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qwen-vs-nanolm" class="md-nav__link">
    <span class="md-ellipsis">
      Qwen vs NanoLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qwen-vs-smollm" class="md-nav__link">
    <span class="md-ellipsis">
      Qwen vs SmolLM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smollm-optimal-learning-rate" class="md-nav__link">
    <span class="md-ellipsis">
      SmolLM optimal learning rate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trained-models-for-longer" class="md-nav__link">
    <span class="md-ellipsis">
      Trained models for longer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#todo" class="md-nav__link">
    <span class="md-ellipsis">
      TODO
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_47_select_instead_of_verify/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 47. Select instead of verify
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_48_more_external_data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 48. More External data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_49_smolLM2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 49. SmolLM2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_50_last_trainings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration 50. Last trainings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iteration n. Iteration_title
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05_Solution_Summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Solution Summary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/00_Challenge_Workflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Challenge workflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/markdown_cheatsheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markdown cheatsheet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/methodology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Methodology
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#goal" class="md-nav__link">
    <span class="md-ellipsis">
      Goal
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#development" class="md-nav__link">
    <span class="md-ellipsis">
      Development
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Development">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#available-options" class="md-nav__link">
    <span class="md-ellipsis">
      Available options
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adding-a-chat-template" class="md-nav__link">
    <span class="md-ellipsis">
      Adding a chat template
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adding a chat template">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#problems-when-adding-the-chat-template" class="md-nav__link">
    <span class="md-ellipsis">
      Problems when adding the chat template
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#local-trainings-to-verify-i-can-train-the-small-models" class="md-nav__link">
    <span class="md-ellipsis">
      Local trainings to verify I can train the small models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debug-long-context-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Debug long context fine-tuning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-when-resuming-training" class="md-nav__link">
    <span class="md-ellipsis">
      Error when resuming training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#problem-with-smollm-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      Problem with SmolLM predictions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    <span class="md-ellipsis">
      Results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#increasing-the-context-length-by-increasing-rope_theta" class="md-nav__link">
    <span class="md-ellipsis">
      Increasing the context length by increasing rope_theta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-evaluation-results" class="md-nav__link">
    <span class="md-ellipsis">
      First evaluation results
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#studying-training-dynamics" class="md-nav__link">
    <span class="md-ellipsis">
      Studying training dynamics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Studying training dynamics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qwen-vs-nanolm" class="md-nav__link">
    <span class="md-ellipsis">
      Qwen vs NanoLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qwen-vs-smollm" class="md-nav__link">
    <span class="md-ellipsis">
      Qwen vs SmolLM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smollm-optimal-learning-rate" class="md-nav__link">
    <span class="md-ellipsis">
      SmolLM optimal learning rate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trained-models-for-longer" class="md-nav__link">
    <span class="md-ellipsis">
      Trained models for longer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#todo" class="md-nav__link">
    <span class="md-ellipsis">
      TODO
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="iteration-46-revisit-small-llms">Iteration 46. Revisit small LLMs</h1>
<p><em>28-10-2024</em></p>
<h2 id="goal">Goal</h2>
<p>Can I train a smaller LLM than Qwen2.5-0.5B to achieve the same accuracy?</p>
<h2 id="motivation">Motivation</h2>
<p>I don't have too many ideas that can be implemented in 2 weeks. If I can train a smaller model than
then 0.5B Qwen then I could do a longer test-time fine-tuning during the submission or do more
inference steps. That could translate to higher LB scores.</p>
<p>I encountered two problems on past iterations:</p>
<ol>
<li>Small models typically have a context length of 2k or less</li>
<li>Some models don't even have a chat template</li>
</ol>
<h2 id="development">Development</h2>
<h3 id="available-options">Available options</h3>
<p>It's quite difficult to search for an LLM with a certain configuration. I have found a <a href="https://huggingface.co/datasets/open-llm-leaderboard/contents/viewer/default/train?sort%5Bcolumn%5D=%23Params+%28B%29&amp;sort%5Bdirection%5D=asc&amp;row=512">leaderboard</a>
that allows to sort by the number of parameters. I have also found <a href="https://github.com/stevelaskaridis/awesome-mobile-llm">awesome-mobile-llm</a>.</p>
<table>
<thead>
<tr>
<th>model</th>
<th>parameters (M)</th>
<th>max_position_embeddings</th>
<th>rope_theta</th>
<th>attention heads</th>
<th>has chat-template?</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://huggingface.co/amd/AMD-Llama-135m">AMD-Llama-135m</a></td>
<td>135</td>
<td>2048</td>
<td>1.00E+04</td>
<td>12</td>
<td>FALSE</td>
</tr>
<tr>
<td><a href="https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct">HuggingFaceTB/SmolLM-135M-Instruct</a></td>
<td>135</td>
<td>2048</td>
<td>1.00E+04</td>
<td>9</td>
<td>TRUE</td>
</tr>
<tr>
<td><a href="https://huggingface.co/Locutusque/TinyMistral-248M-Instruct">TinyMistral-248M-Instruct</a></td>
<td>248</td>
<td>32768</td>
<td>1.00E+04</td>
<td>32</td>
<td>FALSE</td>
</tr>
<tr>
<td><a href="https://huggingface.co/apple/OpenELM-270M">OpenELM-270M</a></td>
<td>270</td>
<td>2048</td>
<td>-</td>
<td>?</td>
<td>FALSE</td>
</tr>
<tr>
<td><a href="https://huggingface.co/Mxode/NanoLM-0.3B-Instruct-v2">Mxode/NanoLM-0.3B-Instruct-v2</a></td>
<td>365</td>
<td>131072</td>
<td>1.00E+06</td>
<td>14</td>
<td>TRUE</td>
</tr>
<tr>
<td><a href="https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct">Qwen2.5-0.5B-Instruct</a></td>
<td>500</td>
<td>32768</td>
<td>1.00E+06</td>
<td>14</td>
<td>TRUE</td>
</tr>
</tbody>
</table>
<p>The SmolLM model has an uneven number of attention heads and VLLM does not support model parallel in that case. However
I might not need to use 2 GPUs for such an small model.</p>
<h3 id="adding-a-chat-template">Adding a chat template</h3>
<p>I have noticed that Qwen has the chat template in the <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/blob/main/tokenizer_config.json#L198">tokenizer_config.json</a>.</p>
<p>It seems that I can simply copy it and assign to the AMD-Llama-135m model. <a href="https://huggingface.co/docs/transformers/main/en/chat_templating#how-do-i-create-a-chat-template">How do I create a chat template?</a></p>
<h4 id="problems-when-adding-the-chat-template">Problems when adding the chat template</h4>
<p>Despite the code being very simple, I get a weird error with the collator. It does not find the keys, although they
are in the text.</p>
<pre><code>  warnings.warn(
/home/gbarbadillo/miniconda3/envs/arc/lib/python3.10/site-packages/trl/trainer/utils.py:198: UserWarning: Could not find instruction key `&lt;|im_start|&gt;user` in the following instance: &lt;s&gt; &lt;|im_start|&gt;system
You are a helpful assistant.&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Let's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.
Below there are some input-output grid examples that define the task.
...
...
&lt;|im_end|&gt;
 This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.
  warnings.warn(
</code></pre>
<h3 id="local-trainings-to-verify-i-can-train-the-small-models">Local trainings to verify I can train the small models</h3>
<details>
  <summary>Click to see bash commands</summary>


<pre><code class="language-bash">python fine-tuning.py \
--model_path /home/gbarbadillo/data/Qwen2.5-0.5B-Instruct \
--output_dir /mnt/hdd0/Kaggle/arc24/models/20241028_debug_small_LLMs/01_Qwen2.5-0.5B-Instruct \
--train_datasets /mnt/hdd0/Kaggle/arc24/data/arc-agi_training_challenges.json output-from-examples-v1 \
--val_dataset /mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json output-from-examples-v1 \
--grid_encoder &quot;GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))&quot; \
--device_map None \
--lora_r 32 \
--max_steps 10 \
--logging_steps 1 \
--eval_steps 200 \
--batch_size 16 \
--learning_rate 1e-4 \
--max_seq_len 4096 \
--no-resume_from_checkpoint \
--random_seed 7 \
--verbose

python fine-tuning.py \
--model_path /home/gbarbadillo/data/NanoLM-0.3B-Instruct-v2 \
--output_dir /mnt/hdd0/Kaggle/arc24/models/20241028_debug_small_LLMs/02_NanoLM-0.3B-Instruct-v2 \
--train_datasets /mnt/hdd0/Kaggle/arc24/data/arc-agi_training_challenges.json output-from-examples-v1 \
--val_dataset /mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json output-from-examples-v1 \
--grid_encoder &quot;GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))&quot; \
--device_map None \
--lora_r 32 \
--max_steps 10 \
--logging_steps 1 \
--eval_steps 200 \
--batch_size 16 \
--learning_rate 1e-4 \
--max_seq_len 4096 \
--no-resume_from_checkpoint \
--random_seed 7 \
--verbose

python fine-tuning.py \
--model_path /home/gbarbadillo/data/SmolLM-135M-Instruct \
--output_dir /mnt/hdd0/Kaggle/arc24/models/20241028_debug_small_LLMs/03_SmolLM-135M-Instruct \
--train_datasets /mnt/hdd0/Kaggle/arc24/data/arc-agi_training_challenges.json output-from-examples-v1 \
--val_dataset /mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json output-from-examples-v1 \
--grid_encoder &quot;GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))&quot; \
--device_map None \
--lora_r 32 \
--max_steps 10 \
--logging_steps 1 \
--eval_steps 200 \
--batch_size 16 \
--learning_rate 1e-4 \
--max_seq_len 4096 \
--no-resume_from_checkpoint \
--random_seed 7 \
--verbose

python fine-tuning.py \
--model_path /home/gbarbadillo/data/AMD-Llama-135m \
--output_dir /mnt/hdd0/Kaggle/arc24/models/20241028_debug_small_LLMs/04_AMD-Llama-135m \
--train_datasets /mnt/hdd0/Kaggle/arc24/data/arc-agi_training_challenges.json output-from-examples-v1 \
--val_dataset /mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json output-from-examples-v1 \
--grid_encoder &quot;GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))&quot; \
--device_map None \
--lora_r 32 \
--max_steps 1 \
--logging_steps 1 \
--eval_steps 200 \
--batch_size 16 \
--learning_rate 1e-4 \
--max_seq_len 1024 \
--no-resume_from_checkpoint \
--random_seed 7 \
--remove_train_samples_to_fit_max_seq_len \
--verbose

</code></pre>


</details>

<h3 id="debug-long-context-fine-tuning">Debug long context fine-tuning</h3>
<p>I'm going to create a temporal fine-tuning script to validate the idea of long context fine-tuning.</p>
<p>The idea is to try with synthetic questions and responses that cannot be answered if not using a big
enough context. If the model has a big enough context answering the questions is trivial. That should
be a very clear test to see if the context window of the model has been extended.</p>
<details>
  <summary>Click to see bash commands</summary>


<pre><code class="language-bash">export model=Qwen2.5-0.5B-Instruct
export prompt_tokens_target=4000

export model=SmolLM-135M-Instruct
export prompt_tokens_target=4000
python long-context-fine-tuning.py \
--prompt_tokens_target ${prompt_tokens_target} \
--model_path /home/gbarbadillo/data/${model} \
--output_dir /mnt/hdd0/Kaggle/arc24/models/20241029_debug_long_context/${model}_${prompt_tokens_target}prompt-length \
--max_steps 30 \
--max_seq_len 4096

export model=SmolLM-135M-Instruct
export prompt_tokens_target=8000
python long-context-fine-tuning.py \
--prompt_tokens_target ${prompt_tokens_target} \
--model_path /home/gbarbadillo/data/${model} \
--output_dir /mnt/hdd0/Kaggle/arc24/models/20241029_debug_long_context/${model}_${prompt_tokens_target}prompt-length_rope-theta-1e5 \
--max_steps 30 \
--max_seq_len 8096

export model=SmolLM-135M-Instruct-20k
export prompt_tokens_target=8000
python long-context-fine-tuning.py \
--prompt_tokens_target ${prompt_tokens_target} \
--model_path /home/gbarbadillo/data/${model} \
--output_dir /mnt/hdd0/Kaggle/arc24/models/20241029_debug_long_context/${model}_${prompt_tokens_target}prompt \
--max_steps 30 \
--max_seq_len 8096
</code></pre>


</details>

<blockquote>
<p>Token indices sequence length is longer than the specified maximum sequence length for this model (2511 &gt; 2048). Running this sequence through the model will result in indexing errors</p>
</blockquote>
<p>TODO: I have proben that by changing rope_theta from 1e4 to 1e5 the model can work with inputs of 8k tokens correctly.</p>
<p>One way of increasing the context window is modifying the model at loading, but that adds complexity
to the training script:</p>
<pre><code>config = AutoConfig.from_pretrained(model_path)
config.max_position_embeddings = 10240
config.rope_theta = 1e5

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    config=config)

tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True,
        model_max_length=10240,
        max_length=10240,)
</code></pre>
<p>The other and maybe easier option is to modify the <code>.json</code> config files of the model and tokenizer.
The result is exactly the same but it does not increase the complexity of the fine-tuning script.</p>
<h3 id="error-when-resuming-training">Error when resuming training</h3>
<blockquote>
<p>Error invalid argument at line 396 in file /src/csrc/pythonInterface.cpp
https://github.com/bitsandbytes-foundation/bitsandbytes/issues/782</p>
</blockquote>
<p>One user says that using <code>adamw_torch</code> solves the issue. And it was true, adding <code>--optim adamw_torch</code> to
the training arguments solved the problem.</p>
<h3 id="problem-with-smollm-predictions">Problem with SmolLM predictions</h3>
<p>I'm facing a weird error with some fine-tuned SmolLM models:</p>
<ol>
<li>I saw NaN losses when retraining in Kaggle</li>
<li>Inference is empty</li>
</ol>
<pre><code class="language-bash">
export model_path=/mnt/hdd0/Kaggle/arc24/models/20241028_training_models/04_full-fine-tune-SmolLM-135M-Instruct-20k_lr2e-4_bs32_40000steps_2gpus_8192msl_adamw-torch/checkpoint-40000
export model_path=/mnt/hdd0/Kaggle/arc24/models/20241028_training_models/07_continue_full-fine-tune-SmolLM-135M-Instruct-20k_lr1e-3_bs16_40000steps_2gpus_8192msl_adamw-torch/checkpoint-40000/
export model_path=/mnt/hdd0/Kaggle/arc24/models/20241031_smollm_learning_rate/lr1e-4_fft-SmolLM-135M-Instruct-20k_bs16_10000steps_1gpus_8192msl/checkpoint-10000
export model_path=/mnt/hdd0/Kaggle/arc24/models/20241028_submission_models/06_fft-SmolLM-135M-Instruct-20k_lr1e-3_bs16_100000steps_2gpus_8192msl/checkpoint-36000
export model_path=/mnt/hdd0/Kaggle/arc24/models/20241028_submission_models/06_fft-SmolLM-135M-Instruct-20k_lr1e-3_bs16_200000steps_2gpus_8192msl/checkpoint-13000
export model_path=/mnt/hdd0/Kaggle/arc24/models/20241028_submission_models/06_fft-SmolLM-135M-Instruct-20k_lr1e-3_bs16_400000steps_2gpus_8192msl/checkpoint-13500

export model_path=/mnt/hdd0/Kaggle/arc24/models/20241028_training_models/08_fft-SmolLM-135M-Instruct-20k_lr1e-3_bs16_100000steps_2gpus_8192msl/checkpoint-100000 &amp;&amp;
python inference.py --model_path ${model_path} --output_filepath /mnt/hdd0/Kaggle/arc24/debug/smollm_problems/debug.json --predictions_per_task 8 --grid_encoder &quot;GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))&quot; --dataset_path /mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json --prompt_version output-from-examples-v1 --temperature 0.0 --n_tasks 1
</code></pre>
<p>After analyzing the output it is always predicting <code>&lt;|endoftext|&gt;</code>, which is the pad token.</p>
<p>There is a workaround that could be tried: https://github.com/vllm-project/vllm/issues/3361</p>
<p>However the problem was that all inference logits were NaNs, so it was selecting the first token
which happened to be <code>&lt;|endoftext|&gt;</code>.</p>
<p>The problem was related to training on <code>bfloat16</code> and doing inference with <code>float16</code>.</p>
<blockquote>
<p>While bfloat16 uses the same number of bits as float16, it has a wider dynamic range but lower precision.</p>
</blockquote>
<p>It seemed that the model was working on a regime where <code>float16</code> fails but <code>bfloat16</code> works due to its
higher dynamic range. That could be solved by using <code>dtype='auto',</code> on VLLM, but I have concerns that in
Kaggle might not work, or work more slowly.</p>
<h2 id="results">Results</h2>
<h3 id="increasing-the-context-length-by-increasing-rope_theta">Increasing the context length by increasing <code>rope_theta</code></h3>
<p>On a synthetic task I have probed that I can increase the context length of <code>SmolLM-135M-Instruct</code>
to be able to work with prompts of 8k tokens by increasing <code>rope_theta</code> from 1e4 to 1e5.</p>
<p><img alt="rope_theta increase" src="../res/2024-10-29-12-34-55.png" /></p>
<p>The plot above shows how quickly the task is learned once the model has enough context window.
Using <code>rope_scaling</code> almost did not have any effect.</p>
<h3 id="first-evaluation-results">First evaluation results</h3>
<table>
<thead>
<tr>
<th>model</th>
<th>lora_r</th>
<th>batch_size</th>
<th>training steps</th>
<th>multi-tasks</th>
<th>accuracy</th>
<th>pass_n</th>
<th>vote_2</th>
<th>vote_1</th>
</tr>
</thead>
<tbody>
<tr>
<td>Qwen2-0.5B</td>
<td>fft</td>
<td>16</td>
<td>4E+04</td>
<td>1</td>
<td>12.25%</td>
<td>31.13%</td>
<td>22.62%</td>
<td>18.50%</td>
</tr>
<tr>
<td>Qwen2-0.5B</td>
<td>32</td>
<td>16</td>
<td>4E+04</td>
<td>1</td>
<td>11.10%</td>
<td>30.25%</td>
<td>22.62%</td>
<td>18.88%</td>
</tr>
<tr>
<td>Qwen2-0.5B</td>
<td>128</td>
<td>16</td>
<td>4E+04</td>
<td>1</td>
<td>12.73%</td>
<td>32.25%</td>
<td>22.25%</td>
<td>19.00%</td>
</tr>
<tr>
<td>Qwen2.5-0.5B</td>
<td>64</td>
<td>32</td>
<td>4E+04</td>
<td>4</td>
<td>8.02%</td>
<td>23.75%</td>
<td>18.12%</td>
<td>12.75%</td>
</tr>
<tr>
<td>Qwen2.5-0.5B</td>
<td>96</td>
<td>32</td>
<td>4E+04</td>
<td>4</td>
<td>7.93%</td>
<td>24.62%</td>
<td>16.38%</td>
<td>12.62%</td>
</tr>
<tr>
<td>NanoLM-0.3B-Instruct-v2</td>
<td>64</td>
<td>32</td>
<td>4E+04</td>
<td>4</td>
<td>3.93%</td>
<td>18.25%</td>
<td>10.50%</td>
<td>7.25%</td>
</tr>
<tr>
<td>NanoLM-0.3B-Instruct-v2</td>
<td>128</td>
<td>32</td>
<td>4E+04</td>
<td>4</td>
<td>5.27%</td>
<td>20.00%</td>
<td>12.88%</td>
<td>9.12%</td>
</tr>
<tr>
<td>SmolLM-135M-Instruct-20k</td>
<td>fft</td>
<td>32</td>
<td>4E+04</td>
<td>4</td>
<td>1.83%</td>
<td>9.00%</td>
<td>5.62%</td>
<td>3.88%</td>
</tr>
</tbody>
</table>
<ul>
<li>First observation is that we are not getting the same results as the baseline Qwen2 models. My believe
  is that the new models are undertrained and they need to be trained for longer. I already have launched
  training continuations.</li>
<li>Second observation is that NanoLM and SmolLM get worse results than Qwen for the same amount of training steps.
  Maybe we have to train the smaller models for longer? I need to think about this.</li>
</ul>
<h3 id="studying-training-dynamics">Studying training dynamics</h3>
<h4 id="qwen-vs-nanolm">Qwen vs NanoLM</h4>
<p><img alt="training dynamics" src="../res/2024-10-31-12-30-48.png" /></p>
<p>NanoLM models learns more slowly than Qwen, but so far there is no sign of plateau and it seems that if trained for longer it would have reached the same point as the bigger model.</p>
<h4 id="qwen-vs-smollm">Qwen vs SmolLM</h4>
<p><img alt="training dynamics" src="../res/2024-10-31-12-37-45.png" /></p>
<p>However the training dynamic of SmolLM is totally different. It learns at teh beginning but quickly decreases
the learning speed. Why could this be happening?</p>
<ul>
<li>Lack of capacity. This might be possible, although the total size of the model is bigger than most of the LoRA adapters that I have trained so far.</li>
<li>Bad learning rate schedule</li>
<li>Local minima, this might be solved with a different learning rate schedule.</li>
</ul>
<h3 id="smollm-optimal-learning-rate">SmolLM optimal learning rate</h3>
<p><img alt="smollm learning rate" src="../res/2024-11-03-08-28-27.png" /></p>
<p>I have found that to fine-tune SmolLM model I have to use a learning rate almost 10 times bigger
than the one I was using.</p>
<p>However at the same time using a higher learning rate could result at a model that fails when using
<code>float16</code> at inference, as shown in this <a href="#problem-with-smollm-predictions">section</a></p>
<h3 id="trained-models-for-longer">Trained models for longer</h3>
<p>I have trained all the models for longer:</p>
<table>
<thead>
<tr>
<th>model</th>
<th>lora_r</th>
<th>batch_size</th>
<th>training steps</th>
<th>multi-tasks</th>
<th>accuracy</th>
<th>pass_n</th>
<th>vote_2</th>
<th>vote_1</th>
</tr>
</thead>
<tbody>
<tr>
<td>Qwen2-0.5B</td>
<td>32</td>
<td>16</td>
<td>4.0E+04</td>
<td>1</td>
<td>11.10%</td>
<td>30.25%</td>
<td>22.62%</td>
<td>18.88%</td>
</tr>
<tr>
<td>Qwen2.5-0.5B</td>
<td>64</td>
<td>16</td>
<td>1.2E+05</td>
<td>4</td>
<td>10.32%</td>
<td>27.62%</td>
<td>19.38%</td>
<td>16.88%</td>
</tr>
<tr>
<td>NanoLM-0.3B-Instruct-v2</td>
<td>128</td>
<td>16</td>
<td>2.0E+05</td>
<td>4</td>
<td>6.38%</td>
<td>23.12%</td>
<td>14.37%</td>
<td>10.88%</td>
</tr>
<tr>
<td>SmolLM-135M-Instruct-20k</td>
<td>fft</td>
<td>16</td>
<td>2.0E+05</td>
<td>4</td>
<td>4.96%</td>
<td>19.62%</td>
<td>13.38%</td>
<td>9.50%</td>
</tr>
</tbody>
</table>
<p>We don't reach the results from the baseline yet, but we are very close. It is likely that we just simply
have to train for a bit longer.</p>
<p>This experiment shows that smaller LLMs do not reach the accuracy of Qwen despite being trained for longer.
Maybe I should go in the opposite direction and try bigger models (although I could not do test-time fine-tuning with them)</p>
<h2 id="conclusion">Conclusion</h2>
<p>Smaller LLMs do not reach results as good as Qwen2.5-0.5B despite being trained for longer. It seems
that we have to go the other direction, try with bigger models instead.</p>
<h2 id="next-steps">Next steps</h2>
<ul>
<li>Try SmolLM2 on a next iteration</li>
</ul>
<h2 id="todo">TODO</h2>
<ul class="task-list">
<li class="task-list-item"><input type="checkbox" disabled checked/> Experiment to validate that I can extend the context window of the model. At the beginning is a simple instruction, then a lot of distraction text. If the model has enough context length the task is trivial, otherwise is impossible.</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> How can I add a chat template to a model?</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Can I reach the same validation results as old Qwen?<ul class="task-list">
<li class="task-list-item"><input type="checkbox" disabled checked/> Qwen2.5<ul class="task-list">
<li class="task-list-item"><input type="checkbox" disabled/> <a href="https://wandb.ai/guillermobarbadillo/20241028_training_models/runs/6wvr45kb">09_lora64-Qwen2.5-0.5B-Instruct_lr1e-4_bs16_120000steps_2gpus_8192msl</a></li>
</ul>
</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Mxode/NanoLM-0.3B-Instruct-v2<ul class="task-list">
<li class="task-list-item"><input type="checkbox" disabled/> <a href="https://wandb.ai/guillermobarbadillo/20241028_training_models/runs/3tj7bhgj?nw=nwuserguillermobarbadillo">10_lora128-NanoLM-0.3B-Instruct-v2_lr1e-4_bs16_200000steps_2gpus_8192msl</a></li>
</ul>
</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> SmolLM-135M-Instruct-20k<ul class="task-list">
<li class="task-list-item"><input type="checkbox" disabled/> <a href="https://wandb.ai/guillermobarbadillo/20241028_training_models/runs/0tvxtzx5">08_fft-SmolLM-135M-Instruct-20k_lr1e-3_bs16_400000steps_2gpus_8192msl</a></li>
</ul>
</li>
</ul>
</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Make SmolLM great again, do multiple short trainings with different learning rate schedules</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> ~~Does it help to pretrain SmolLM-20k model on text?~~ Cancelled because SmolLM2 was released.<ul class="task-list">
<li class="task-list-item"><input type="checkbox" disabled checked/> Datasets for long context fine-tuning. https://huggingface.co/blog/wenbopan/long-context-fine-tuning#long-text-data</li>
</ul>
</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Check the problem of dtype on Kaggle. Is <code>float32</code> or <code>bfloat16</code> slower on Kaggle? No problem was found.</li>
</ul>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    2024-11-06
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/guillermobarbadillo/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/guille_bar" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/channel/UCOHmUwHnd2hmUpiDzaQ1Isg" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.kaggle.com/ironbar" target="_blank" rel="noopener" title="www.kaggle.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M304.2 501.5 158.4 320.3 298.2 185c2.6-2.7 1.7-10.5-5.3-10.5h-69.2c-3.5 0-7 1.8-10.5 5.3L80.9 313.5V7.5q0-7.5-7.5-7.5H21.5Q14 0 14 7.5v497q0 7.5 7.5 7.5h51.9q7.5 0 7.5-7.5v-109l30.8-29.3 110.5 140.6c3 3.5 6.5 5.3 10.5 5.3h66.9q5.25 0 6-3z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.525ec568.min.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>